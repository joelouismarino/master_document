\chapter{Graphical Models}

\section{Basics}

\section{Dynamical Directed Latent Variable Models}
\label{sec: dynamic directed latent variable models}

To model a sequence of $T$ observations, $\mathbf{x}_{1:T}$, one can use a dynamical latent variable model, $p_\theta (\mathbf{x}_{1:T}, \mathbf{z}_{1:T})$, which models the joint distribution between $\mathbf{x}_{1:T}$ and a sequence of latent variables, $\mathbf{z}_{1:T}$, with parameters $\theta$. Using a directed graphical model, $p_\theta (\mathbf{x}_{1:T}, \mathbf{z}_{1:T})$ can be factorized into conditional joint distributions, $p_\theta (\mathbf{x}_t, \mathbf{z}_t | \mathbf{x}_{1:t-1}, \mathbf{z}_{1:t-1})$, at each time step $t$, which are conditioned on all preceding variables:
\begin{equation}
    p_\theta (\mathbf{x}_{1:T}, \mathbf{z}_{1:T}) = \prod_{t=1}^T p_\theta (\mathbf{x}_t, \mathbf{z}_t | \mathbf{x}_{1:t-1}, \mathbf{z}_{1:t-1}) = \prod_{t=1}^T p_\theta (\mathbf{x}_t | \mathbf{x}_{1:t-1}, \mathbf{z}_{1:t}) p_\theta (\mathbf{z}_t | \mathbf{x}_{1:t-1}, \mathbf{z}_{1:t-1}).
    \label{eq: general dynamics model}
\end{equation}
A plate notation diagram for the full graphical model is shown in Figure \ref{fig: full_dynamical_model}. The distribution $p_\theta (\mathbf{x}_t | \mathbf{x}_{1:t-1}, \mathbf{z}_{1:t})$ is commonly referred to as the observation or measurement model, and $p_\theta (\mathbf{z}_t | \mathbf{x}_{1:t-1}, \mathbf{z}_{1:t-1})$ is the dynamics or transition model. Conditioning through a direct functional dependence on all past variables requires a method of storing and accessing this information, which becomes intractable, in terms of both memory and computation, as the sequence length grows. To overcome this intractability, the model is typically assumed to be Markovian, meaning that
\begin{itemize}
    \item the states form a Markov sequence, $p_\theta (\mathbf{z}_t | \mathbf{x}_{1:t-1}, \mathbf{z}_{1:t-1}) = p_\theta (\mathbf{z}_t | \mathbf{z}_{t-1}) $, and
    \item the observations are conditionally independent of all other latent variables and observations given the current latent variable, $p_\theta (\mathbf{x}_t | \mathbf{x}_{1:t-1}, \mathbf{z}_{1:t}) = p_\theta (\mathbf{x}_t | \mathbf{z}_t)$.
\end{itemize}
In other words, it is assumed that the latent variable at a particular time step contains all of the information necessary to summarize the corresponding observation and all future and past latent variables. Eq. \ref{eq: general dynamics model} then becomes:
\begin{equation}
    p_\theta (\mathbf{x}_{1:T}, \mathbf{z}_{1:T}) = \prod_{t=1}^T p_\theta (\mathbf{x}_t, \mathbf{z}_t | \mathbf{z}_{t-1}) = \prod_{t=1}^T p_\theta (\mathbf{x}_t | \mathbf{z}_{t}) p_\theta (\mathbf{z}_t | \mathbf{z}_{t-1}).
    \label{eq: markov dynamics model}
\end{equation}
A plate notation diagram for the updated model is shown in Figure \ref{fig: markov_dynamical_model}.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{images/graphical_models/full_dynamical_model.png}
        \caption{ }
        \label{fig: full_dynamical_model}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{images/graphical_models/markov_dynamical_model.png}
        \caption{ }
        \label{fig: markov_dynamical_model}
    \end{subfigure}
    \caption{Plate notation diagrams for dynamical latent variable models with (a) all temporal dependencies and (b) the Markov assumption. Plates denote that there are $N$ example sequences. Parameters $\theta$ have been omitted for clarity.}
\end{figure*}

\subsection{Bayesian Filtering}

Dynamical directed latent variable models naturally lend themselves to a \textit{filtering} setting \cite{sarkka2013bayesian}, in which one computes the marginal posterior distribution, $p(\mathbf{z}_t | \mathbf{x}_{1:t})$, at each time step. This corresponds to estimating the current state of the system given all past observations. Under the Markov assumption (eq. \ref{eq: markov dynamics model}), we start with a latent prior, $p_\theta (\mathbf{z}_1)$, and compute the marginal posterior at some time step $t$ by recursively applying the following steps:
\begin{enumerate}
	\item \textbf{Prediction}: use the Chapman-Kolmogorov equation to form a prior (i.e. prediction) on the latent variable at the next time step: 
\begin{equation}
	p(\mathbf{z}_t | \mathbf{x}_{1:t-1}) = \int p_\theta (\mathbf{z}_t | \mathbf{z}_{t-1}) p_\theta (\mathbf{z}_{t-1} | \mathbf{x}_{1:t-1}) d\mathbf{z}_{t-1}.
\end{equation}
	\item \textbf{Update}: use the prediction, along with Bayes' rule, to update the marginal posterior:
\begin{equation}
	p(\mathbf{z}_t | \mathbf{x}_{1:t}) = \frac{p_\theta (\mathbf{x}_t | \mathbf{z}_t) p_\theta (\mathbf{z}_t | \mathbf{x}_{1:t-1})}{p_\theta (\mathbf{x}_{1:t})},
\end{equation}
	where $p_\theta (\mathbf{x}_{1:t})$ is calculated as
\begin{equation}
	p_\theta (\mathbf{x}_{1:t}) = \int p_\theta (\mathbf{x}_t | \mathbf{z}_t) p_\theta (\mathbf{z}_t | \mathbf{x}_{1:t-1}) d\mathbf{z}_t.
\end{equation}
\end{enumerate}
When $p_\theta (\mathbf{x}_t | \mathbf{z}_t)$ and $p_\theta (\mathbf{z}_t | \mathbf{x}_{1:t-1})$ are parameterized as linear functions that take a Gaussian form, the resulting model is referred to as a Kalman filter \cite{kalman1961new}. However, in general, the prediction and update steps are both intractable, as they involve integrating over the space of latent variables. To overcome these intractabilities, one must turn to forms of approximate inference (see Section \ref{sec: variational inference in dynamical models}).

% The joint prior distribution of the states is given as:
% \begin{equation}
% 	p(z_{0:T}) = p(z_0) \prod_{t=1}^T p(z_t | z_{t-1}).
% \end{equation}
% The joint conditional likelihood of measurements is given as:
% \begin{equation}
% 	p(x_{1:T} | z_{0:T}) = \prod_{t=1}^T p(x_t | z_t).
% \end{equation}
% The full posterior (which is intractable) is given as:
% \begin{equation}
%	p(z_{0:T} | x_{1:T}) = \frac{p(x_{1:T} | z_{0:T}) p(z_{0:T})}{p(x_{1:T})}.
% \end{equation}

\subsection{Beyond the Markov Assumption}
While drastically simplifying the model, the Markov assumption is often invalid in practical settings, where one commonly encounters partial observations (i.e. hidden information) or correlated observation noise across time. In such cases, the ``memoryless" or ``static world" properties of the Markov assumption no longer hold, requiring that we expand the model to condition on past variables. This can be accomplished through
\begin{itemize}
	\item conditioning on a concatenation of variables containing the recent trajectory,
	\item memory mechanisms that selectively store state information \cite{chung2015recurrent, fraccaro2016sequential, gemici2017generative},
	\item modeling the observations and latent variables in generalized coordinates \cite{friston2010generalised}.
\end{itemize}

\section{Transformation of Variables}
\label{sec: transformation of variables}

Real-valued non-volume preserving (Real NVP) transformations provide a tractable method of performing learning and inference in a non-linear latent variable model \cite{dinh2016density}. With a bijective generative mapping $g$, latent variable $\mathbf{z} \sim p_z (\mathbf{z})$, and observation $\mathbf{x} \sim p_x (\mathbf{x})$, the density over observations can be modeled using the transformation of variables formula:
\begin{equation}
	p_x (\mathbf{x}) = p_z (\mathbf{z}) \bigg \vert \text{det} \left( \frac{\partial g(\mathbf{z})}{\partial \mathbf{z}^T} \right) \bigg \vert^{-1}.
	\label{eq: real nvp transform of variables 1}
\end{equation}
Using the bijection $f = g^{-1}$, equation \ref{eq: real nvp transform of variables 1} can also be written as
\begin{equation}
	p_x (\mathbf{x}) = p_z (f(\mathbf{x})) \bigg \vert \text{det} \left( \frac{\partial f(\mathbf{x})}{\partial \mathbf{x}^T} \right) \bigg \vert 
	\label{eq: real nvp transform of variables 2}
\end{equation}
\begin{equation}
	\log \left( p_x (\mathbf{x}) \right) = \log \left( p_z (f(\mathbf{x})) \right)  + \log \left( \bigg \vert \text{det} \left( \frac{\partial f(\mathbf{x})}{\partial \mathbf{x}^T} \right) \bigg \vert \right).
	\label{eq: real nvp transform of variables 3}
\end{equation}
Because the mapping between $\mathbf{x}$ and $\mathbf{z}$ is invertible, we can perform exact inference and evaluation with the model. Also note that evaluation of the log-likelihood, $\log \left( p_x (\mathbf{x}) \right)$, does not require a fixed-form reconstruction cost, such as $L^2$ distance, because the terms on the right side of eq. \ref{eq: real nvp transform of variables 3} can be computed using the data, mapping, and prior. Inference and generation procedures are shown for a simple two dimensional example in Figure \ref{fig: transform of variables}.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/graphical_models/transform_of_variables.png}
    \caption{Inference and generation through transformation of variables in 2D. The invertible mapping between the observed and latent variables warps the respective spaces. Reproduced from \cite{dinh2016density}.}
    \label{fig: transform of variables}
\end{figure}

In general, computing eq. \ref{eq: real nvp transform of variables 3} is intractable for high-dimensional variables, stemming from computing the log determinant of the Jacobian matrix. However, by carefully designing the mapping, we can achieve a lower triangular Jacobian matrix, the determinant of which is simply the product of the diagonal elements. Given a $D$ dimensional input $\mathbf{x}$ and $d < D$, an \textit{affine coupling layer} with output $\mathbf{y}$ is defined as 
\begin{align}
	\mathbf{y}_{1:d} &= \mathbf{x}_{1:d},
	\label{eq: real nvp mapping 1} \\
	\mathbf{y}_{d+1:D} &= \mathbf{x}_{d+1:D} \odot \exp (s(\mathbf{x}_{1:d})) + t(\mathbf{x}_{1:d}),
	\label{eq: real nvp mapping 2}
\end{align}
where $s(\mathbf{x}_{1:d})$ and $t(\mathbf{x}_{1:d})$ are respectively \textit{scale} and \textit{translation} functions from $\mathbb{R}^d \rightarrow \mathbb{R}^{D-d}$. The Jacobian of this transformation is
\begin{equation}
	\frac{\partial \mathbf{y}}{\partial \mathbf{x}^T} =
	\begin{bmatrix}
    \mathbf{I}_d & 0 \\
    \frac{\partial \mathbf{y}_{d+1:D}}{\partial \mathbf{x}^T_{1:d}}  & \text{diag} \left( \exp \left( s(\mathbf{x}_{1:d}) \right) \right)
\end{bmatrix}.
\end{equation}
Therefore, the determinant of the Jacobian can be easily computed as
\begin{equation}
	\text{det} \left( \frac{\partial \mathbf{y}}{\partial \mathbf{x}^T}  \right) = \exp \left( \sum_j s(\mathbf{x}_{1:d})_j \right).
\end{equation}
Note that $s$ and $t$ can be any arbitrary functions, as only their output values enter into inference and evaluation. Furthermore, the mapping in eqs. \ref{eq: real nvp mapping 1} and \ref{eq: real nvp mapping 2} can be inverted without computing the inverse of $s$ or $t$:
\begin{align}
	\mathbf{x}_{1:d} &= \mathbf{y}_{1:d}, \\
	\mathbf{x}_{d+1:D} &= (\mathbf{y}_{d+1:D} - t(\mathbf{x}_{1:d})) \odot \exp (- s(\mathbf{x}_{1:d})).
\end{align}
By composing multiple coupling layers, one can construct more expressive transformations. Successive coupling layers alternate between transforming different subsets of the input dimensions. The determinants of the Jacobians, as well as the inverse mappings, can still be computed easily. The authors of \cite{dinh2016density} use checkerboard and channel-wise masked convolutional networks to implement $s$ and $t$, with a hierarchy of resolutions. Other possible transformations are possible instead of coupling layers, such as normalizing and inverse auto-regressive flow.

NICE: \cite{dinh2014nice}







