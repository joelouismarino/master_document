\chapter{Intelligence}

\section{Defining Intelligence}

The purpose of this manuscript is to build a common base of knowledge for understanding \textit{intelligence} across all systems, both biological and non-biological. To understand what makes a system intelligent, we must first define intelligence. Intelligence is a fuzzy term that carries many varying connotations. Our everyday notion of intelligence fails to objectively capture this attribute in the most general sense of the term.

Let's start by stating that intelligence is the property of a \textit{system}, which we define as a collection of matter. Systems can exist on different scales and can be composed: 

\begin{center}
	\textbf{Intelligence} is the ability of a system to convert energy into work to alter the trajectory of the universe. 
\end{center}

Consider the concepts of \textit{matter}, \textit{state}, and \textit{energy}. Matter, here, is the normal, everyday matter that we encounter, which is composed of atoms. The state defines the configuration of the matter, consisting of the location and motion of every atom. Energy is a more difficult concept, that 


Under certain conditions, a \textit{system}, composed of matter, can convert energy into work. This allows the system to alter its own state, as well as the state of the matter in the surrounding \textit{environment}. We can then ask which states can and cannot be reached as a result of the work performed. It is precisely the ability to reach a particular state, or set of states, that we define as \textit{intelligence}. In this sense, intelligence is only defined in the context of a state transition. If a system can achieve a given state transition, which we refer to as a \textit{task}, then it is intelligent with respect to that task. While intelligence can be defined for any task, the main task that we find in naturally occurring systems is reproduction. Tautologically, a system that is unable to reproduce (or survive indefinitely) will eventually be destroyed and no longer exist.



Let us start by stating that intelligence is the property of a \textit{system}. We restrict our discussion to the physical realm, where a system is defined as a collection of matter, such as a biological organism or a designed machine. However, more generally, the notion of a system could also be applied within abstract or virtual worlds. 

\textit{Need to define intelligence. Need to first discuss basics of energy and entropy.}

Note that very few physical systems are intelligent. Beyond our planet, it seems that the universe is not conducive for intelligent systems. 

\subsection{Maxwell's ``Demon"}

Maxwell's demon is the simplest example of an intelligent system....?

Some definitions of intelligence from AIXI: \cite{legg2007universal}

Douglas Hofstadter's \cite{hofstadter1980godel} essential abilities of an intelligent system (reproduced):
\begin{itemize}
    \item to respond to situations very flexibly;
    \item to take advantage of fortuitous circumstances;
    \item to make sense out of ambiguous or contradictory messages;
    \item to recognize the relative importance of different elements of a situation;
    \item to find similarities between situations despite differences which may separate them;
    \item to draw distinctions between situations despite similarities which may link them;
    \item to synthesize new concepts by taking old concepts and putting them together in new ways;
    \item to come up with ideas which are novel.
\end{itemize}

I define intelligence as follows:

Intelligence is a quality that must be measured. It does not exist in a vacuum, independent from an external environment. The only way in which to measure the intelligence of a system is through its ability to solve tasks, which depends on the system's outputs within the environment. Intelligence is not one particular thing, but rather a \textit{space} with a multitude of dimensions. As it is defined according to solving tasks, a system can be intelligent with regards to some tasks but not others. It is also important to note that solving a task may not be an all-or-none phenomenon. A system may be able to solve a task to a certain percentage of success and it would still be considered intelligent.

The notion of solving tasks gets at the deeper concept of environmental \textit{states}. The surrounding environment of an intelligent system can be in an infinite number of underlying states. Considering every possible arrangement of matter, most of these states will be highly disordered. The second law of thermodynamics dictates that the state of the environment will tend toward these disordered states, as they are more probable. In other words, entropy tends to increase overall. \textbf{``Solving a task" denotes arriving at some environmental state or set of states (a macro-state).} The probability of the state, in some sense, then defines the difficulty of the task. 

As an example, say that your task is to be at the other end of the room. In the entire universe, ``you at the other end of the room" defines an infinite set of states. However, there are \textit{infinitely many more} states where you are not at the other end of the room, and according to Newton's first law, you will stay where you are unless acted on by a force. Without a force, it is therefore improbable that the state of the environment will be one in which you are at the other end of the room. But because you are a system that is built to solve this task, you can arrive at this improbable environmental macro-state.

The task for natural, biological systems is clear: \textbf{survive}, ideally long enough to reproduce and ensure the survival of the offspring. Survival is indeed the \textit{only} task for intelligent systems in the natural world, as it is the only task that results in persisting intelligent systems. An intelligent system that is not capable of surviving is eventually destroyed, again, due to the second law of thermodynamics. There are infinitely many states that consist of a system's survival, but there are infinitely many more states that consist of a system's demise. As such, we observe systems in the natural world that are highly specialized to ensure their own survival.

A key question in creating intelligent machines will be what tasks they are expected to perform. While biological systems are built for survival, this need not be the case for any arbitrary intelligent system. Of course, we will likely create machines that are capable of ensuring their own survival, as this is more cost-effective and less wasteful. It is just important to point out that this is not necessarily the default operating mode. We could just as easily create intelligent machines that have no preference for their own survival. Intelligent systems are also not inherently good or evil. It is the tasks that they are built to perform that determine their actions. Coming up with the desired set of tasks and specifying these tasks clearly is an important consideration for building intelligent machines.

Intelligence is also not unique to contiguous collections of matter. Intelligence can be a property of systems more generally. The many devices that we have created assist in augmenting our intelligence. For instance, with a car, we can travel long distances in short amounts of time. Neither the car nor the person can do this on its own. Rather, the car-person system as a whole possesses the intelligence. Likewise, groups of people can be intelligent in ways beyond any single person. No one person constructs a skyscraper or sends people to the moon. It is the group system that is able to solve those tasks; it is the group system that is intelligent. This is relevant, as it highlights that we should not restrict intelligence to a measure of a single entity. A non-biological intelligent system can be much more than one standalone machine.



\section{Intelligent Systems Perform Work}

Work processes, both in biological and non-biological systems, require energy. Through converting energy into useful work, such systems bring about change, both to the system itself, as well as the environment in which the system interacts. Importantly, work comes in many forms, and in biological systems, work can be studied at many hierarchical levels. To understand work, we must first understand energy through the laws of thermodynamics:
\begin{enumerate}
    \item \textbf{First Law of Thermodynamics}: Energy cannot be created or destroyed; it is conserved. However, energy can be transformed from one form into another. This conversion process is called \textit{energy transduction}, and is an important process in biological and non-biological systems. The first law does not specify how work is converted, but does specify a \textit{performance envelope} dictating how much work a system can perform.
    
    \item \textbf{Second Law of Thermodynamics}: Roughly, order in the universe is, on average, constantly decreasing. Thus, for a highly ordered system to exist, it must require a constant input of energy. This allows the system to oppose the tendency toward disorder by maintaining and repairing itself.
    
    \item \textbf{Third Law of Thermodynamics}: Temperature fundamentally characterizes how work gets done. It plays an important role in defining the performance envelope of a system. Thus, systems must often spend considerable energy maintaining their temperature, whether it be a biological organism or an office building.
\end{enumerate}

Through the process of energy transduction, a system can convert energy into \textit{potential energy}, which can then be converted into \textit{useful work}. For instance, one could use an energy input to pump water up a mountain, thereby converting the energy into potential energy. Using the flow of water down the mountain, one could convert this energy into the work of spinning a turbine. A similar work process is ubiquitous in biological systems.

\subsection{Cellular Work Processes in Biological Systems}

Energy is required to perform the work of sustaining the order within biological systems. How is this energy obtained and converted? In animals, energy comes from organic nutrients, such as glucose, which are the result of breaking down foods. In plants, energy is instead obtained from the sun through photosynthesis, then converted into organic nutrients. In biological systems, these organic nutrients are broken down step by step and carried through intermediate molecules, which then convert the energy into useful work. The main intermediate (or carrier) molecule in biological systems is ATP, adenosine triphosphate. Breaking down nutrients involves oxidation, which yields electrons. These electrons are used for \textit{proton pumping}, moving protons from one side of a cell membrane to the other. This creates a concentration gradient across the cell membrane. Using channels, which can harness the resulting flow of protons back across the membrane, the cell performs the work of ATP synthesis, combining adenosine diphosphate (ADP) and inorganic phosphate (P$_i$). This entire process is referred to as \textit{chemiosmosis}. ATP can then be converted into other forms of work, such as protein synthesis or muscular work. Chemiosmosis thus forms the foundation of work in biological systems, and cells are working constantly to maintain stockpiles of ATP. Note also that this process is highly temperature dependent. Chemiosmosis is highly conserved across all domains of biological organisms, and likely provided a fundamental step in further evolutionary development.


\section{The Future of Intelligence}

Predicting the future is notoriously difficult. Since the advent of computing machines, many experts have made wildly inaccurate predictions about intelligent machines. On the one hand, constructing a machine that is capable of behaving like a human seems so plausible, even obvious. On the other, we currently don't have the faintest idea of how our own intelligence works. \textbf{Intelligent machines are an obvious invention that we don't know how to build.} This ability to \textit{visualize} intelligent machines without \textit{realizing} them opens the door to speculation.

Rodney Brooks identifies seven deadly sins\footnote{https://rodneybrooks.com/the-seven-deadly-sins-of-predicting-the-future-of-ai/} of predicting the future of artificial intelligence. He starts by noting four areas in which there is hype and hysteria in the public:
\begin{itemize}
	\item \textbf{Artificial General Intelligence}: building general-purpose machines that can solve a variety of tasks, much in the same way that humans operate.
	\item \textbf{The Singularity}: the inflection point when intelligent machines start creating better intelligent machines.
	\item \textbf{Misaligned Values}: intelligent machines that interpret directions too literally or without common-sense understanding, going against our intentions.
	\item \textbf{``Evil" Intelligent Machines}: intelligent machines that purposefully destroy humans.
\end{itemize}
Brooks then goes on to identify seven deadly sins:
\begin{enumerate}
	\item \textbf{Over and Under Estimating}: We often have a difficult time estimating how a technology will play out. This is nicely summarized by Roy Amara's quote:
	
	\textit{We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run.}
	
	In other words, we often set too high of expectations upfront, then fail to estimate how impactful a technology will be down the road. Brooks gives the example of GPS, which took decades until it proved its usefulness, but it now an essential part of many aspects of society. 
	\item \textbf{Imagining Magic}: Future technologies are so far in the future that we simply do not have to ability to reason about their capabilities. This is encapsulated in Arthur C. Clark's third ``law":
	
	\textit{Any sufficiently advanced technology is indistinguishable from magic.}
	
	That is, reasoning about the capabilities of technologies in the distant future is somewhat like reasoning about magic; it's just not possible. Brooks gives the example of Isaac Newton being introduced to an iPhone. He would be astounded to see it producing light, capturing images, etc., and he would be unable to judge whether other capabilities, such as communicating with other people or transforming lead into gold, are reasonable.
	\item \textbf{Performance vs. Competence}: We are typically able to judge the \textit{competence} of humans based on their \textit{performance} on other tasks. For instance, if you can drive a manual transmission car, I should expect that you are also able to drive an automatic transmission car. These types of competence generalization assumptions do not hold up for machine systems, which we, as humans, find unintuitive.
	\item \textbf{Suitcase Words}: Marvin Minsky defines suitcase words as those that pack many different meanings, such as imagine, plan, reason, understand, recognize, and even learn. We are so accustomed to human intelligence that we tend to ascribe these words to intelligent machines, even when they only apply narrowly.
	\item \textbf{Exponentials}: People often use exponential trends to justify predictions about rapid progress in technology, particularly computing and intelligent machines. Brooks argues that Moore's Law is not a true ``law" and will not continue indefinitely. More broadly, technological exponential trends are often really just the start of an S-curve, and they tend to flatten out or fail for three reasons: (1) physical limits, (2) market demand, (3) they may not be exponential in the first place. Predicting the future of intelligent machines based on exponential trends is highly imprecise.
	\item \textbf{Hollywood Scenarios}: Many popular movies about intelligent machines in the future often picture these machines in our current technological landscape, often failing to imagine how other technologies will change. That is, there will be a series of technological innovations to get to wherever we end up; it will not be some sudden change.
	\item \textbf{Speed of Deployment}: The pace of deployment for hardware is much slower than that for software. This is due to higher capital costs, which places limits on the widespread adoption of technologies. Brooks identifies instances in factory automation technology and defense where technology is 20 to 50 years old and incredibly resistant to change. 
\end{enumerate}











